import { supabase } from './utils/supabase.js';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

const targets = [
  { name: 'ì•ˆì‚°ì—”ë¹„ì˜ì›', hid: '1267b395-1132-4511-a8ba-1afc228a8867' },
  { name: 'ë™ì•ˆì¤‘ì‹¬ì˜ì›', hid: '7b169807-6d76-4796-a31b-7b35f0437899' },
  { name: 'í¬ì—ë²„ì˜ì›(ì‹ ì‚¬)', hid: '92f7b52a-66e9-4b1c-a118-6058f89db92e' },
];

async function main(): Promise<void> {
  const outDir = path.resolve(__dirname, 'data', 'v4-test3', 'screenshots');
  if (!fs.existsSync(outDir)) fs.mkdirSync(outDir, { recursive: true });

  for (const t of targets) {
    const { data: pages } = await supabase
      .from('hospital_crawl_pages')
      .select('page_type, screenshot_url')
      .eq('hospital_id', t.hid)
      .not('screenshot_url', 'is', null)
      .order('crawled_at');

    if (!pages) continue;

    const safeName = t.name.replace(/[()]/g, '').replace(/\s+/g, '-');

    for (const p of pages) {
      if (!p.screenshot_url) continue;
      try {
        const resp = await fetch(p.screenshot_url);
        const buf = Buffer.from(await resp.arrayBuffer());
        const fileName = `${safeName}_${p.page_type}.webp`;
        const filePath = path.resolve(outDir, fileName);
        fs.writeFileSync(filePath, buf);
        console.log(`âœ… ${fileName} (${(buf.length / 1024).toFixed(1)}KB)`);
      } catch (err) {
        console.log(`âŒ ${t.name} ${p.page_type}: ${err}`);
      }
    }
  }

  console.log(`\nğŸ“ ì €ì¥ ìœ„ì¹˜: ${outDir}`);
}

main().catch(console.error);
